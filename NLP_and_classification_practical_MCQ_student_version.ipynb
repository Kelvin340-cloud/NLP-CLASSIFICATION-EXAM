{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2352555",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Python-Notebook-Banners/Code_challenge.png\"  style=\"display: block; margin-left: auto; margin-right: auto;\";/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f662d169",
   "metadata": {},
   "source": [
    "# Practical MCQ: NLP and classification\n",
    "© ExploreAI Academy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26af890c",
   "metadata": {},
   "source": [
    "In this train, we'll explore and evaluate different machine learning classifiers through various tasks like model fitting, parameter tuning, and performance comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d230d14",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Learning objectives\n",
    "\n",
    "By the end of this notebook, you should be able to:\n",
    "\n",
    "- Utilise vectorisation techniques to process textual data.\n",
    "- Implement logistic regression and measure its accuracy.\n",
    "- Determine optimal model parameters using grid search.\n",
    "- Interpret the output of machine learning models using confusion matrices.\n",
    "- Analyse the performance of classifiers with precision-recall metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8863c65d",
   "metadata": {},
   "source": [
    "> ⚠️ Please note that the multiple choices to all questions are not included in this notebook; they are available exclusively on the MCQ webpage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0b7683",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fecec55",
   "metadata": {},
   "source": [
    "What does the `CountVectorizer` output `X` represent in the code snippet below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc759b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample text data\n",
    "data = [\"Machine learning is fascinating.\", \"Natural language processing and machine learning are closely linked.\"]\n",
    "\n",
    "# Initialise the CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the data\n",
    "X = vectorizer.fit_transform(data)\n",
    "\n",
    "# Get the feature names\n",
    "feature_names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ccb80d",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Modify the code below to compute and print the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "419ad301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialise the Logistic Regression model\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Train the model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set results\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da9d0dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Logistic Regression Model is: 0.958041958041958\n"
     ]
    }
   ],
   "source": [
    "# insert code here\n",
    "# Calculate the accuracy score of the Model\n",
    "print(f\"The accuracy of the Logistic Regression Model is: {accuracy_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dc9de7",
   "metadata": {},
   "source": [
    "What is the accuracy of the logistic regression model on the test data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd508e27",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "What is the value of True Positive (TP) in the confusion matrix generated by the RandomForestClassifier below? Modify the code to print the value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bae0e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Generate synthetic binary classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize and train the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set results\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e25577a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Confusion Matrix is:\n",
      "\n",
      " [[107   8]\n",
      " [ 22 113]]\n",
      "\n",
      "True Negative value: 107\n",
      "False Positive value: 8\n",
      "False Negative value: 22\n",
      "True Positive value: 113\n"
     ]
    }
   ],
   "source": [
    "# insert code here\n",
    "# Display the confusion matrix \n",
    "print(f\"The Confusion Matrix is:\\n\\n {cm}\")\n",
    "\n",
    "# Access the TP, FP, TN, FN in the confusion matrix\n",
    "TN = cm[0,0]\n",
    "FP = cm[0, 1]\n",
    "FN = cm[1, 0]\n",
    "TP  = cm[1,1]\n",
    "\n",
    "# Display the output\n",
    "print(f\"\\nTrue Negative value: {TN}\")\n",
    "print(f\"False Positive value: {FP}\")\n",
    "print(f\"False Negative value: {FN}\")\n",
    "print(f\"True Positive value: {TP}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93542c5b",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "What is the best value of the parameter 'C' for the SVC according to the grid search? Modify the code to print the best parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b03d1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SVC(kernel=&#x27;linear&#x27;),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SVC(kernel=&#x27;linear&#x27;),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(kernel='linear'),\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "# Load a dataset\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Initialize an SVC (Support Vector Classifier) with a linear kernel\n",
    "svm = SVC(kernel='linear')\n",
    "\n",
    "# Define parameter range for C (regularization parameter)\n",
    "param_grid = {'C': np.logspace(-3, 3, 7)}\n",
    "\n",
    "# Setup the grid search with cross-validation\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit grid search\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6a41522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.001}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert code here\n",
    "# Print the best value of the parameter C\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98217731",
   "metadata": {},
   "source": [
    "## Question 5 \n",
    "\n",
    "Which code snippet can be used to fill in the missing lines of code to train the SVM classifier, predict the test set results, and print the classification report?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "64ac91d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Classifiaction reporrt is as follows:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       115\n",
      "           1       0.89      0.81      0.85       135\n",
      "\n",
      "    accuracy                           0.84       250\n",
      "   macro avg       0.84      0.85      0.84       250\n",
      "weighted avg       0.85      0.84      0.84       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate a synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize the SVM classifier with a radial basis function kernel\n",
    "svm_rbf = SVC(kernel='rbf')\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "# [Your Code Here] - Line to add for fitting the model\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set results\n",
    "# [Your Code Here] - Line to add for making predictions\n",
    "svm_pred = svm_rbf.predict(X_test)\n",
    "\n",
    "# Generate and print the classification report\n",
    "# [Your Code Here] - Line to add for printing the classification report\n",
    "print(f\"The Classifiaction reporrt is as follows:\\n\\n {classification_report(y_test, svm_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e875cb9",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Given the code below, your task is to select the function from the options provided that correctly completes the task by:\n",
    "\n",
    "i) Creating a function that determines which classifier (KNN or Naive Bayes) has a higher F1 score, or if they have equal scores.\n",
    "\n",
    "ii) Printing the name of the classifier along with its F1 score in the format: 'ClassifierName has the higher F1 score of Score' or 'Both classifiers have the same F1 score of Score'.\n",
    "\n",
    "iii) Executing the function.\n",
    "\n",
    "Select the appropriate code snippet from the options below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6953839e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN has higher F1 score 0.8065\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Generate a synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize KNN and Naive Bayes classifiers\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "nb = GaussianNB()\n",
    "\n",
    "# Train both classifiers on the training data\n",
    "knn.fit(X_train, y_train)\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set results for both classifiers\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "\n",
    "# Calculate F1 scores for both classifiers\n",
    "f1_knn = f1_score(y_test, y_pred_knn)\n",
    "f1_nb = f1_score(y_test, y_pred_nb)\n",
    "\n",
    "# [Your Code Here]\n",
    "def best_classifier(f1_knn, f1_nb):\n",
    "    if f1_knn > f1_nb:\n",
    "        print(f'KNN has higher F1 score {f1_knn:.4f}')\n",
    "    elif f1_nb > f1_knn:\n",
    "        print(f\"Naive Bayes has a higher F1 score {f1_nb:.4f}\")\n",
    "    else:\n",
    "        print(f\"Both Classifeir have the same F1 score {f1_knn:.4f}\")\n",
    "        \n",
    "# Invoking the function\n",
    "best_classifier(f1_knn, f1_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9667f9",
   "metadata": {},
   "source": [
    "## Question  7 \n",
    "\n",
    "Which of the following options will complete the missing code lines to:\n",
    "\n",
    "i) train the MLPClassifier, \n",
    "\n",
    "ii) predict the test set labels,\n",
    "\n",
    "iii) count the number of misclassified samples,\n",
    "\n",
    "iv) call the function to print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b4c48cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of misclassified samples are: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Generate a two-moon dataset\n",
    "X, y = make_moons(n_samples=1000, noise=0.2, random_state=42)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialise the MLPClassifier with one hidden layer with 10 neurons\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10,), max_iter=1000, random_state=42)\n",
    "\n",
    "# [Your Code Here] - Train the MLPClassifier on the scaled training data\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "# [Your Code Here] - Predict the labels for the scaled test data\n",
    "mlp_pred  = mlp.predict(X_test_scaled)\n",
    "\n",
    "# [Your Code Here] - Print the number of misclassified samples in the test set\n",
    "# Count the number of misclassified samples\n",
    "misclassified_samples = np.sum(mlp_pred != y_test)\n",
    "print(f\"The number of misclassified samples are: {misclassified_samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8065ab7",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "\n",
    "Before running the final line of the code in the snippet below to fit the `grid_search` object, you are asked to perform the following tasks directly in the code:\n",
    "\n",
    "1. Modify the `param_grid` to include a new parameter: `'max_features'` with values ranging from 1 to 4.\n",
    "2. Fit the `grid_search` to the training data.\n",
    "3. After fitting, extract and print the best parameter combination and the corresponding cross-validation score.\n",
    "\n",
    "Which of the following options correctly completes these tasks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eba25b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter combination:\n",
      "\n",
      "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=42),\n",
      "             param_grid={'max_depth': [None, 10, 20, 30],\n",
      "                         'max_features': [1, 2, 3, 4],\n",
      "                         'min_samples_split': [2, 10, 20]})\n",
      "\n",
      "Best cross-validation F1 score: 0.9372\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Setup a basic decision tree classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Define a parameter grid over which to optimize the decision tree\n",
    "param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 10, 20],\n",
    "    'max_features': [1, 2, 3, 4]\n",
    "}\n",
    "\n",
    "# Setup the GridSearchCV\n",
    "grid_search = GridSearchCV(dt, param_grid, cv=5)\n",
    "\n",
    "# fit tghe grid_search to the training data\n",
    "best_params = grid_search.fit(X_train, y_train)\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "\n",
    "# Print the best parameter\n",
    "print(f'Best parameter combination:\\n\\n{best_params}')\n",
    "print(f'\\nBest cross-validation F1 score: {best_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b112d7e",
   "metadata": {},
   "source": [
    "## Question 9\n",
    "\n",
    "You are fine-tuning a decision tree classifier for a marketing dataset. To prevent overfitting and ensure robust generalisability, you must adjust the depth of the decision tree after its initialisation but before it is fitted with data. Considering the decision tree `dt` has already been initialised with a random state, which of the following is the correct way to modify the tree's maximum depth?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "38372bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=5, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=5, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5, random_state=42)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialise decision tree classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# [Your Code Here\n",
    "# Adjust the max_depth of the tree to prevent over fitting\n",
    "dt.max_depth = 5\n",
    "\n",
    "# Fit the tree to the training data \n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537192ee",
   "metadata": {},
   "source": [
    "## Question 10\n",
    "\n",
    "Suppose you are analysing the performance of a new email spam detection system using precision and recall. You have already computed these metrics, and you are about to explore their trade-offs to optimise the classifier's threshold. Given the code snippet below, identify the correct function call that would allow you to adjust and visualise the precision-recall trade-off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b858357c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAAIhCAYAAABdSTJTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABQuElEQVR4nO3deVhWdf7/8dfhZke5TVFEBUHN1DAzNbfMtLK0LLOFlskla7JmKnPq+xObbB1xWpxWbXGrqYyp1LLMsrFM0wq30rQswcHlRsPlBgWR5fz+QO68BdEb4T4ceD6u677GcziH877vA83Lj5/z/himaZoCAAAAbCjA6gIAAACAqiLMAgAAwLYIswAAALAtwiwAAABsizALAAAA2yLMAgAAwLYIswAAALAtwiwAAABsizALAAAA2yLMAqgxc+bMkWEYnldgYKBatWql0aNHa+fOnX6vZ9SoUYqPj/fpnG3btskwDM2ZM6dGajqZUaNGeX2GwcHBatu2rR544AHl5ORYUtOxKvp8yu77tm3bTul7/Pjjjxo9erQSEhIUGhqqBg0a6LzzztNTTz2lffv21UzhAOqMQKsLAFD3zZ49Wx06dFB+fr6+/vprpaSkaNmyZdqwYYMiIiL8VsfDDz+s++67z6dzYmJitGrVKrVt27aGqjq5sLAwLV26VJJ04MABvf/++3r22Wf1448/6vPPP7esrurw+uuv6+6779ZZZ52lBx98UJ06dVJhYaFWr16tV155RatWrdL8+fOtLhNALUaYBVDjEhMT1b17d0nSgAEDVFxcrCeeeEILFizQLbfcUuE5eXl5Cg8Pr9Y6qhJIQ0JC1KtXr2qtw1cBAQFeNVx++eVKT0/XkiVLlJGRoYSEBAurq7pVq1bprrvu0qWXXqoFCxYoJCTE87VLL71Uf/vb37R48eJquVZ+fr5CQ0NlGEa1fD8AtQfTDAD4XVkw+9///iep9J/SGzRooA0bNmjQoEFq2LChLr74YknSkSNH9OSTT6pDhw4KCQlR06ZNNXr0aP3+++/lvu8777yj3r17q0GDBmrQoIHOPfdczZw50/P1iqYZvPfee+rZs6ecTqfCw8PVpk0b3XbbbZ6vn2iawYoVK3TxxRerYcOGCg8PV58+ffTJJ594HVP2z+1ffvml7rrrLkVFRalJkyYaPny4du3aVeXPT5LnLwe7d+/22p+amqrevXsrIiJCDRo00GWXXaZ169aVO/+7777T0KFD1aRJE4WGhqpt27YaN26c5+u//fabRo8erTPPPFPh4eFq2bKlhg4dqg0bNpxW3ceaPHmyDMPQa6+95hVkywQHB+uqq67ybBuGoUcffbTccfHx8Ro1apRnu+xz//zzz3XbbbepadOmCg8PV2pqqgzD0H//+99y32P69OkyDEM//vijZ9/q1at11VVXqXHjxgoNDVXXrl31n//85/TeNIBqR5gF4He//fabJKlp06aefUeOHNFVV12lgQMH6sMPP9Rjjz2mkpISXX311ZoyZYpuvvlmffLJJ5oyZYqWLFmiiy66SPn5+Z7zJ02apFtuuUUtWrTQnDlzNH/+fI0cOdITmCuyatUqJSUlqU2bNnr33Xf1ySefaNKkSSoqKqq0/mXLlmngwIFyu92aOXOm5s6dq4YNG2ro0KFKTU0td/ztt9+uoKAgvfPOO3rqqaf01Vdf6U9/+pOvH5uXjIwMBQYGqk2bNp59kydP1k033aROnTrpP//5j/79738rNzdX/fr106ZNmzzHffbZZ+rXr58yMzM1depUffrpp/r73//uFYx37dqlJk2aaMqUKVq8eLFefvllBQYGqmfPnvrll19Oq3ZJKi4u1tKlS9WtWzfFxsae9veryG233aagoCD9+9//1vvvv69rrrlGzZo10+zZs8sdO2fOHJ133nk655xzJElffvml+vbtqwMHDuiVV17Rhx9+qHPPPVdJSUmWzZ8GcAImANSQ2bNnm5LMb7/91iwsLDRzc3PNjz/+2GzatKnZsGFDMysryzRN0xw5cqQpyZw1a5bX+XPnzjUlmR988IHX/rS0NFOSOW3aNNM0TTM9Pd10OBzmLbfcUmk9I0eONFu3bu3ZfuaZZ0xJ5oEDB054TkZGhinJnD17tmdfr169zGbNmpm5ubmefUVFRWZiYqLZqlUrs6SkxOv933333V7f86mnnjIlmS6Xq9J6y2qOiIgwCwsLzcLCQjM7O9ucPn26GRAQYE6cONFzXGZmphkYGGjec889Xufn5uaazZs3N2+44QbPvrZt25pt27Y18/PzT3r9Y9/fkSNHzDPPPNO8//77Pfsr+nzK3ndGRsYJv19WVpYpybzxxhtPuQZJ5iOPPFJuf+vWrc2RI0eWu/6IESPKHTt+/HgzLCzM655v2rTJlGS++OKLnn0dOnQwu3btahYWFnqdf+WVV5oxMTFmcXHxKdcNoGYxMgugxvXq1UtBQUFq2LChrrzySjVv3lyffvqpoqOjvY679tprvbY//vhjNWrUSEOHDlVRUZHnde6556p58+b66quvJElLlixRcXGx/vKXv/hUV48ePSRJN9xwg/7zn/+cUoeFQ4cO6bvvvtN1112nBg0aePY7HA7deuut2rFjR7mRy2P/qVySZ/SvbNS4pKTE6/0VFxeXu2ZQUJCCgoIUFRWlu+66S0lJSfrHP/7hOeazzz5TUVGRRowY4fW9QkND1b9/f89ntWXLFm3dulVjxoxRaGjoCd9nUVGRJk+erE6dOik4OFiBgYEKDg7Wr7/+qs2bN5/0c6oNjv95kkpHa/Pz871G0GfPnq2QkBDdfPPNkkr/5eDnn3/2zOc+9vMcMmSIXC5XtYxOA6gehFkANe7NN99UWlqa1q1bp127dunHH39U3759vY4JDw9XZGSk177du3frwIEDCg4O9oS5sldWVpays7MlyTN/tlWrVj7VdeGFF2rBggWeENiqVSslJiZq7ty5Jzxn//79Mk1TMTEx5b7WokULSdLevXu99jdp0sRru2x+aNk0iccff9zrvR3/oFpYWJjS0tKUlpamhQsX6qKLLtLcuXM1ZcoUzzFlUwR69OhR7rNKTU31+bMaP368Hn74YQ0bNkwLFy7Ud999p7S0NHXp0sVrekdVRUVFKTw8XBkZGaf9vU6kont09tlnq0ePHp6pBsXFxXrrrbd09dVXq3HjxpL++CwfeOCBcp/l3XffLUmezxOA9ehmAKDGdezY0fPA0olU9JR52QNTJ3qivWHDhpL+mHu7Y8cOn+dfXn311br66qtVUFCgb7/9VikpKbr55psVHx+v3r17lzv+jDPOUEBAgFwuV7mvlT3UFRUV5VMNf/7zn3XllVd6to9/GCogIMDr87v00kvVrVs3PfbYY7rlllsUGxvrueb777+v1q1bn/Bax35WlXnrrbc0YsQITZ482Wt/dna2GjVqdErvqzIOh0MXX3yxPv30U+3YseOU/iISEhKigoKCcvuP/8tDmRN1Lhg9erTuvvtubd68Wenp6XK5XBo9erTn62WfZXJysoYPH17h9zjrrLNOWi8A/yDMAqi1rrzySr377rsqLi5Wz549T3jcoEGD5HA4NH369AoD6KkICQlR//791ahRI3322Wdat25dhd8rIiJCPXv21Lx58/TMM88oLCxMUulUgbfeekutWrVS+/btfbp2ixYtPKO6p1rryy+/rIsuukhPPvmkXn31VV122WUKDAzU1q1bK/zn9TLt27dX27ZtNWvWLI0fP77CLgJSaRA8/muffPKJdu7cqXbt2p1yrZVJTk7WokWLdMcdd+jDDz9UcHCw19cLCwu1ePFiDR06VFJp14Jjuw1I0tKlS3Xw4EGfrnvTTTdp/PjxmjNnjtLT09WyZUsNGjTI8/WzzjpLZ555pn744YdyYR5A7UOYBVBr3XjjjXr77bc1ZMgQ3XfffTr//PMVFBSkHTt26Msvv9TVV1+ta665RvHx8Zo4caKeeOIJ5efn66abbpLT6dSmTZuUnZ2txx57rMLvP2nSJO3YsUMXX3yxWrVqpQMHDuj5559XUFCQ+vfvf8K6UlJSdOmll2rAgAF64IEHFBwcrGnTpmnjxo2aO3euX3qZ9u/fX0OGDNHs2bM1YcIEJSQk6PHHH9dDDz2k9PR0XX755TrjjDO0e/duff/994qIiPB8Di+//LKGDh2qXr166f7771dcXJwyMzP12Wef6e2335ZU+heJOXPmqEOHDjrnnHO0Zs0aPf300z5P5ahM7969NX36dN19993q1q2b7rrrLp199tkqLCzUunXr9NprrykxMdETZm+99VY9/PDDmjRpkvr3769NmzbppZdektPp9Om6jRo10jXXXKM5c+bowIEDeuCBBxQQ4D3r7tVXX9XgwYN12WWXadSoUWrZsqX27dunzZs3a+3atXrvvfeq7XMAcJqsfgINQN1V9lR5WlpapceVPbFfkcLCQvOZZ54xu3TpYoaGhpoNGjQwO3ToYN55553mr7/+6nXsm2++afbo0cNzXNeuXb2esj++m8HHH39sDh482GzZsqUZHBxsNmvWzBwyZIi5fPlyzzEVPa1vmqa5fPlyc+DAgWZERIQZFhZm9urVy1y4cOEpvf8vv/zSlGR++eWXlX4uJ/tsNmzYYAYEBJijR4/27FuwYIE5YMAAMzIy0gwJCTFbt25tXnfddeYXX3zhde6qVavMwYMHm06n0wwJCTHbtm3r1aVg//795pgxY8xmzZqZ4eHh5gUXXGAuX77c7N+/v9m/f/9KP59T6WZwrPXr15sjR4404+LizODgYDMiIsLs2rWrOWnSJHPPnj2e4woKCsz/+7//M2NjY82wsDCzf//+5vr160/YzaCyn7vPP//clGRKMrds2VLhMT/88IN5ww03mM2aNTODgoLM5s2bmwMHDjRfeeWVU3pfAPzDME3TtCxJAwAAAKeBbgYAAACwLcIsAAAAbIswCwAAANsizAIAAMC2CLMAAACwLcIsAAAAbKveLZpQUlKiXbt2qWHDhn5pbA4AAADfmKap3NxctWjRotyiJserd2F2165dPq/dDgAAAP/bvn37SVcerHdhtmHDhpJKP5zIyEiLqwEAAMDxcnJyFBsb68ltlal3YbZsakFkZCRhFgAAoBY7lSmhPAAGAAAA2yLMAgAAwLYIswAAALAtwiwAAABsizALAAAA2yLMAgAAwLYIswAAALAtwiwAAABsizALAAAA2yLMAgAAwLYIswAAALAtwiwAAABsizALAAAA2yLMAgAAwLYsDbNff/21hg4dqhYtWsgwDC1YsOCk5yxbtkzdunVTaGio2rRpo1deeaXmCwUAAECtZGmYPXTokLp06aKXXnrplI7PyMjQkCFD1K9fP61bt04TJ07Uvffeqw8++KCGKz09Lne+Vm7NlsudX2uu4Y+aqqI2flZWXaM23CO7vI+a+Pn3x+/U8edY8VlVR92+ft0fddaG3x8A/hFo5cUHDx6swYMHn/Lxr7zyiuLi4vTcc89Jkjp27KjVq1frmWee0bXXXltDVZ6el5b+qmc/3yJTkiHpT73i1LddVLVe45vfsvXWt5mnfA1fj/cXf9Rll2vUhntkl/dREz///vidOv6cnm0a67v0fX79rKpyzZO915r4ufG1zmPPDzCklOGdldQjzqcaANiHYZqmaXURkmQYhubPn69hw4ad8JgLL7xQXbt21fPPP+/ZN3/+fN1www3Ky8tTUFBQuXMKCgpUUFDg2c7JyVFsbKzcbrciIyOr9T0cz+XOV5+UpaoVHzAA1FMBhvTNhIGKcYZZXQqAU5STkyOn03lKec3SkVlfZWVlKTo62mtfdHS0ioqKlJ2drZiYmHLnpKSk6LHHHvNXiV4ysg9VGGTbRzdQZGj54F0VOYcLtWX3wVO+hq/H+4s/6rLLNWrDPbLL+6iJn39//E6d6BxfvoevquOaJ3uvNflzc6rfs6LzS0xp/fYDhFmgjrJVmJVKR3CPVTawfPz+MsnJyRo/frxnu2xk1h8SoiIUYJT+h7SMwzD0xm3nV9t/VF3ufPWdsvSUr+Hr8f7ij7rsco3acI/s8j5q4uffH79TFZ1zPH98Vr5e82TvtaZ+bnyp80TnP/rhT4o9I1yJLZ2nVAcA+7BVa67mzZsrKyvLa9+ePXsUGBioJk2aVHhOSEiIIiMjvV7+EuMMU8rwznIcDdoOw9Dk4YnVGkh8vYY/aqqK2vhZWXWN2nCP7PI+auLn3x+/UxWdc+15Lf3+Wfl6zZO915r6ufGlzuPPDzCkqAbB2p1boOtfWaVPN7hOuRYA9mCrObP/7//9Py1cuFCbNm3y7Lvrrru0fv16rVq16pSu48scjOricudrW3ae4qPCayyQ+HoNf9RUFbXxs7LqGrXhHtnlfdTEz78/fqeOP8eKz6o66vb16/6o89jjw4MD9dd31mr5r9mSpPGXttc9A9ud8F/0AFjPl7xmaZg9ePCgfvvtN0lS165dNXXqVA0YMECNGzdWXFyckpOTtXPnTr355puSSltzJSYm6s4779Qdd9yhVatWaezYsZo7d+4pdzOwIswCAKxVVFyifyzarNnfbJMkXXlOjJ6+rovCgh3WFgagQr7kNUunGaxevVpdu3ZV165dJUnjx49X165dNWnSJEmSy+VSZmam5/iEhAQtWrRIX331lc4991w98cQTeuGFF2ptWy4AQO0Q6AjQI0PPVsrwzgoMMPTxjy7d8OoqZbkPW10agNNUa6YZ+AsjswBQv32bvld3vbVG+/MK1axhiF4b0V3nxjayuiwAx7DNyCwAAP7Wq00TffTXC9Q+uoH25BYo6dVV+nD9TlYNA2yKkVkAQL2Ue7hQ495dr//+vEdS6epirBoG1A6MzAIAcBINQ4P02oju+lOv1pLkWeSmxJQmztvICC1gE4RZAEC95QgwNKRz83L7i01T27LzLKgIgK8IswCAei0hKkLHt5x1GIbio8KtKQiATwizAIB6LcYZprH923i2a8vKiABODWEWAFDvXdIxWpIUHRmiFRMG8PAXYCOEWQAAjgoNctT5EVlakKGuCbS6AAAAUDGXO18Z2YeUEBVxyiH7+HOO3f56y+9KnrdBJSYtyFB3EGYBAPCTk4VTX4NnSYmp/MJiHTpSpPwjxZq/dqeeX/qrTLO0b273+DO0ett+mfqjj67n3KMtyC5s37TOj0ajbiPMAgBw1OHCYrnc+acU7nwZNTVNU29/l6lJH25UiSkZhjS2fxv1bhOlvCNFOlRQrOW//q4P1+9SRSsZlZjS//tgg15ZtlWFxabyj5QG2MOFJSe+pqS0bfu9to9X1oKMMAs7I8wCAOq9LzbvliTtzilQ3ylLlTK8s67vFqtDR4p0sKBIBw8f/d+jf1768x69v2aHZ8SzZ5vGauEM08GCoqPnFOtQQZHyCv44r+SYNGma0vSv0jX9q3Sf6sw4Qe9bw5CCHQEqKDpxuK1IgCFakMH2WM4WAFCvudz56jNlqaz4f8O4xuFq1jBER4pL9OMOd6XHBhjS8zeeq1ZnhCs8OFDhwY6jr0CFBgUoK+ew+k5Z6hWaj2ccnWtQdsiQzs017ZZu1fZ+gOriS15jZBYAUK9lZB+qNMgGBhhqEBqoBiGlL9M09cvug+WOu6VnrDq1cCoiOFARIYGKCHGoQUigwoMDlVdQpGHTvvEKmg7DUOqdvTwPaR0fRA1DMkypRH/0vh3apeUJ64xxhilleGdNnLdRxaYph2FoWNcWWrBul2d78vBEXdi+qd74Zpte+Tpd36XvU96RIoUHEwdgX/z0AgDqtYSoCAUY8gqSAYa08J4L1LZpA4UEBsg4ZomwioKnwzD014FnVjr39PigeezCDBUF0bLguS07T/FR4ac0rzWpR1y5cx647Kxy3+OBy87Spz9l6X978/TWt//Tny9s6+OnBtQeTDMAANR7qWmZ5YJkZS2rfD2+jMudX2k4PdnXq9N7q7frwfd/VJOIYC3/fwMqHZ2tSosw4HT4ktcIswAAyPcg6c/gWROKikt08dRl+t/ePN3SM05/HdjO8z7oTQurEWYrQZgFAKDUg+/9oPfW7JBUOkf3hu6tdLiwRB+doEWYVDqlYsWEAbYM8LAPHgADAACVcrnz9cHaHZ5t05RS03ZUckYpetOitgmwugAAAOB/GdmHKm3jdSKGpFZnhFZ7PUBVEWYBAKiHyro4HCvAKA2rxzIM77BgSnr0o03KP1JcwxUCp4YwCwBAPVTWDsxxtO2YwzCUMryzplzrvW/K8M76Jnmg5t7RS09de45CAgP035/36NaZ38mdV2jlWwAk8QCY1eUAAGCpiroyVNapIW3bPo2Zk6acw0VqH91Ab97WU82dTDtA9aKbQSUIswAAnJ6fs3I0ctb32p1ToJaNwvTM9V1kyqQPLaoNYbYShFkAAE7fjv15GjHze6VnH/Lsow8tqosveY05swAAwGetzgjXSzd39dpXYkoT522Uy51vUVWojwizAACgSg7kl38ArKwPLeAvhFkAAFAlFbX3chiG4qPCrSkI9RJhFgAAVElZe68yAYY0eXgiD4HBrwizAACgypJ6xKlJRLAkac6o83n4C35HmAUAAKfFcXSuQVTDEEmlfWpXbs3mQTD4RaDVBQAAAHsrLint8pmdW6DUtEwlz9ugEpNWXfAPwiwAAKiy1LRM7T10RJI0cvb3OrZ5fVmrrgvbN2UeLWoM0wwAAECVuNz5Sp63wbNd0SpMtOpCTSPMAgCAKsnIPqSSk6wjGmCIVl2oUYRZAABQJRX1mTUM73DRKSaSKQaoUYRZAABQJWV9Zh1GaaJ1GIamDO+sb5IH6qlrz5EhaeOuHH2bvtfaQlGnGaZpnuQfCOqWnJwcOZ1Oud1uRUZGWl0OAAC253Lna1t2nuKjwr1GYf++YIPe+jZTnWIitfCeCzwtvICT8SWvMTILAABOS4wzTL3bNik3nWD8pWepYWigNrly9M9PN9N3FjWCMAsAAGpE44hgXXhmU0nSa8sz1HfKUqWmZVpcFeoawiwAAKgRLne+Pt3o8myX9Z1lhBbViTALAABqREWtu+g7i+pGmAUAADWiotZdktS6Ca26UH0IswAAoEYc37qrTNq2/RZVhLoo0OoCAABA3ZXUI04Xtm+qbdl5+uqX3Xr16wz945PNGtihmRqGBlldHuoARmYBAECNKmvdNX7QWUqIitCe3AI998WvVpeFOoIwCwAA/CIk0KFHrzpbkjRn5Tb9nJVjcUWoCwizAADAb/q3b6rBic1VXGLq4QUbVc8WIkUNIMwCAAC/evjKTgoLciht237NX7fT6nJgc4RZAADgVy0ahenei8+UJE1etFnu/MIauY7Lna+VW7NZpKGOI8wCAAC/G3NBgto2jVD2wSP615ItPp9/sqCampapvlOW6ubXv2MZ3TrOMOvZZJWcnBw5nU653W5FRkZaXQ4AAPXWN79l65YZ3ynAkD766wVKbOn0fM3lzldG9iElREUoxhnmtf31lt+VPG+DSkwpwJDuuqidzm4RqV0H8rXzQL7Sfz+oZVuyva7lMAytmDBAMU4WbLADX/IafWYBAIAl+raL0pXnxOjjH12a8MGPSh7cUW2alQ+rfdtFacWv2apo9K3ElF7+8reTXqtsGV3CbN1DmAUAAJb5+xWd9PlPWdq4K0e3zPyu3NdLTGn5r9kVnOmtfXQDndU8Ui0ahapBSKCmLtmiY//tOcCQ4qPCq7N01BKEWQAAYBlTpgqLT2/Go8Mw9MZt53uNujZrGOIZ3ZWkfmdGMSpbR/EAGAAAsExG9qEKpw9UxjD+CDAOw9Dk4YnlgmpSjzh9M2GgHhjUXlLp6O4Xm3d7PTRGt4O6gZFZAABgmYSoCAUY8oygSqVh1TClEpWG1WFdW2jBul0qNk1PeL2wfVNty85TfFT4CUdcY5xh+uvAM/XrnoP6cP0u3f7GakmlUw6u6dpS89ft9MzLTRneWUk94vzwjlHd6GYAAAAslZqWqYnzNlYaVl3u/JOG1xPZ7MrR4OeXV3oM3Q5qF7oZAAAA20jqEVfhSOuxwTLGGVbloLk/78hJj6HbgX0RZgEAgOVOJ6yeTEVTGY5n0O3AtngADAAA1GkxzjClDO8sh2FIKp1ScO15LT3bkhQUYKiwqF7NvKwzmDMLAADqhePn3brc+Ur//ZCeXvyL1u84oHNjG+nBQWepTbMIphtYzJe8RpgFAAD1WubePF0y9SsdOdrvlu4G1vMlrzHNAAAA1GtBgYbXwg0lpjRx3kb6z9oEYRYAANRrFS3cUNbdALUfYRYAANRrZd0OjuUwDLob2ARhFgAA1Gtl3Q7KBBiqcIlc1E6EWQAAUO8l9YhTh+YNJUlPX9+Fh79shDALAAAA2yLMAgCAei81LVM/Z+VKkh547welpmVaXBFOFWEWAADUay53vpLnbfBsm7TmshXCLAAAqNcysg+p5LjeXLTmsg/CLAAAqNdozWVvhFkAAFCv0ZrL3gizAACg3kvqEae2TSMkSQ9d0ZHWXDZCmAUAAPVealqmtv5+SJL05Ceb6WZgI4RZAABQr9HNwN4IswAAoF6jm4G9EWYBAEC9RjcDeyPMAgCAeo1uBvZmeZidNm2aEhISFBoaqm7dumn58uWVHv/yyy+rY8eOCgsL01lnnaU333zTT5UCAIC6im4G9mVpmE1NTdW4ceP00EMPad26derXr58GDx6szMyKnyCcPn26kpOT9eijj+qnn37SY489pr/85S9auHChnysHAAB1Cd0M7MswTdM8+WE1o2fPnjrvvPM0ffp0z76OHTtq2LBhSklJKXd8nz591LdvXz399NOefePGjdPq1au1YsWKU7pmTk6OnE6n3G63IiMjT/9NAAAAW3O589V3ylKvh8AchqEVEwYw1cAivuQ1y0Zmjxw5ojVr1mjQoEFe+wcNGqSVK1dWeE5BQYFCQ0O99oWFhen7779XYWHhCc/JycnxegEAAJShm4G9WRZms7OzVVxcrOjoaK/90dHRysrKqvCcyy67TDNmzNCaNWtkmqZWr16tWbNmqbCwUNnZ2RWek5KSIqfT6XnFxsZW+3sBAAD2RTcDe7P8ATDD8P7pMU2z3L4yDz/8sAYPHqxevXopKChIV199tUaNGiVJcjgcFZ6TnJwst9vteW3fvr1a6wcAAPZGNwN7syzMRkVFyeFwlBuF3bNnT7nR2jJhYWGaNWuW8vLytG3bNmVmZio+Pl4NGzZUVFRUheeEhIQoMjLS6wUAAHCspB5x6tC8oSTp6eu70M3ARiwLs8HBwerWrZuWLFnitX/JkiXq06dPpecGBQWpVatWcjgcevfdd3XllVcqIMDyQWYAAAD4WaCVFx8/frxuvfVWde/eXb1799Zrr72mzMxMjR07VlLpFIGdO3d6eslu2bJF33//vXr27Kn9+/dr6tSp2rhxo9544w0r3wYAALC51LRM/ZyVK0l64L0fVFRcwuisTVgaZpOSkrR37149/vjjcrlcSkxM1KJFi9S6dWtJksvl8uo5W1xcrGeffVa//PKLgoKCNGDAAK1cuVLx8fEWvQMAAGB3Lne+kudt8GybpjRx3kZd2L4p82ZtwNI+s1agzywAADjWyq3Zuvn178rtn3tHL/Vu28SCimCLPrMAAAC1Aa257I0wCwAA6jVac9kbYRYAANR7tOayL8IsAACApCBHaSxqHBFscSXwBWEWAAAAtkWYBQAAgG0RZgEAAGBbhFkAAADYFmEWAABAUmFxiSRp36EjFlcCXxBmAQBAvZealqmfs3IlSQ+894NS0zItrginijALAADqNZc7X8nzNni2TVOaOG+jXO58C6vCqSLMAgCAei0j+5BKTO99xaapbdl5Jz3X5c7Xyq3ZBF8LBVpdAAAAgJUSoiIUYKhcoA0NKj/m53LnKyP7kBKiIvT1lt+VPG+DSszSJXBThndm5TALGKZpmic/rO7IycmR0+mU2+1WZGSk1eUAAIBaIDUtUxPnbVTxMbGofXQDTRzcUWfFNFSMM0ypaZme8GpIOj5AOQxDKyYMUIwzzK+110W+5DVGZgEAQL2X1CNOF7Zvqm3ZeQoJNHTrzO+1ZfdBjZqTJkPS2S0itXFXjuf4ikYCy6YmEGb9izALAAAgKcYZphhnmFzufOUVFnv2m5JXkD0Rh2EoPiq8BitERXgADAAA4BgZ2Yd0KpMwjWP+7DAMTR6eyKisBQizAAAAxyh7IOxYDsNQ8uAOchiGZ/u2CxIkSc0ahmje3b15+MsihFkAAIBjxDjDlDK8s1dwnTw8UXf2b6sVEwZo7h29tGLCAM/xe3ILdM20lSy0YBG6GQAAAFTA5c7Xtuw8xUeFl5s+4HLnq8+UpV7TEehmUH3oZgAAAHCayh4Iq0hF82rpZmANphkAAAD4KCEqQkYF82rpZuB/hFkAAAAfxTjDdFvfBM823QysQ5gFAACogv7tm0qS4hqHa8WEAXQzsAhhFgAA4DREhAQyImshwiwAAABsizALAAAA2yLMAgAAwLYIswAAAKfhUEGRXO58q8uotwizAAAAVbBsy++SpMx9eeo7ZSnL2VqEMAsAAOAjlztfs77J8GyXmNLEeRsZobUAYRYAAMBHlS1nC/8izAIAAPiI5WxrD8IsAACAj1jOtvYgzAIAAFQBy9nWDoRZAACA08ByttYizAIAAMC2CLMAAACwLcIsAAAAbIswCwAAANsizAIAAMC2CLMAAACwLcIsAAAAbIswCwAAANsizAIAAFQTlztfK7dmy+XOt7qUeiPQ6gIAAADs7FBBkXbuz9N7a3bo+S9+lSkpwJBShndmiVs/IMwCAABUwbItv0uSMvflqe8/v/T6WokpTZy3URe2b8pStzWMaQYAAAA+crnzNeubjEqPKTZNbcvO81NF9RdhFgAAwEcZ2YdkmpUf4zAMxUeF+6egeowwCwAA4KOEqAgFGN77jGO2DUmThycyxcAPCLMAAAA+inGGKWV4ZzmOJliHYWjK8M6aekMXSVLLRqE8/OUnPAAGAABQBUk94nRh+6balp2n+KhwxTjDdCDviCRpx4HD2n/oiM6ICLa4yrqPkVkAAIAqinGGqXfbJp7pBI3Cg5UQFSFJ+mHHAQsrqz8IswAAANXo3NhGkqT12w9YWkd9QZgFAACoRl1aOSURZv2FMAsAAFCNzo07Q5L0w/YDMk/WvwunjTALAABQjTrGNFSwI0D78wqVuY9FE2oaYRYAAKAahQQ61KlFpCSmGvgDYRYAAKCalT0Eti7zgKV11AeEWQAAgGpWFmZpz1XzCLMAAADVrCzM/rQrR0eKSqwtpo4jzAIAAFSz1k3CdUZ4kI4UlWizK8fqcuo0wiwAAEA1MwxDXZhq4BeEWQAAgBrQpVUjSdKSn3bL5c63tpg6jDALAABQA3IOF0qSlv+Wrb5Tlio1LdPiiuomwiwAAEA1c7nz9cbKbZ7tElOaOG8jI7Q1gDALAABQzTKyD6nkuJVsi01T27JZEay6EWYBAACqWUJUhAIM730Ow1B8VLg1BdVhhFkAAIBqFuMMU8rwzp7tAEOaPDxRMc4wC6uqmwizAAAANSCpR5ycoYGSpLdv76mkHnEWV1Q3EWYBAABqSMDRuQZNG4ZYXEndRZgFAACAbRFmAQAAYFuEWQAAgBpScrQ/1++5BRZXUncRZgEAAGpAalqm3IeLJEm3zPiOFcBqCGEWAACgmrnc+Uqet8GzzQpgNYcwCwAAUM1YAcx/CLMAAADVjBXA/IcwCwAAUM1YAcx/CLMAAAA1gBXA/MPyMDtt2jQlJCQoNDRU3bp10/Llyys9/u2331aXLl0UHh6umJgYjR49Wnv37vVTtQAAAKeOFcBqnqVhNjU1VePGjdNDDz2kdevWqV+/fho8eLAyMytuXbFixQqNGDFCY8aM0U8//aT33ntPaWlpuv322/1cOQAAAGoDS8Ps1KlTNWbMGN1+++3q2LGjnnvuOcXGxmr69OkVHv/tt98qPj5e9957rxISEnTBBRfozjvv1OrVq/1cOQAAAGoDy8LskSNHtGbNGg0aNMhr/6BBg7Ry5coKz+nTp4927NihRYsWyTRN7d69W++//76uuOKKE16noKBAOTk5Xi8AAAB/YAWwmmdZmM3OzlZxcbGio6O99kdHRysrK6vCc/r06aO3335bSUlJCg4OVvPmzdWoUSO9+OKLJ7xOSkqKnE6n5xUbG1ut7wMAAKAirADmH1UKs4cOHdLDDz+sPn36qF27dmrTpo3XyxeG4d2EzTTNcvvKbNq0Sffee68mTZqkNWvWaPHixcrIyNDYsWNP+P2Tk5Pldrs9r+3bt/tUHwAAgK9YAcx/Aqty0u23365ly5bp1ltvVUxMzAnDZ2WioqLkcDjKjcLu2bOn3GhtmZSUFPXt21cPPvigJOmcc85RRESE+vXrpyeffFIxMTHlzgkJCVFICE8QAgAA/6lsBTB6zVavKoXZTz/9VJ988on69u1b5QsHBwerW7duWrJkia655hrP/iVLlujqq6+u8Jy8vDwFBnqX7HA4JJWO6AIAANQGZSuAHRtoAwyxAlgNqNI0gzPOOEONGzc+7YuPHz9eM2bM0KxZs7R582bdf//9yszM9EwbSE5O1ogRIzzHDx06VPPmzdP06dOVnp6ub775Rvfee6/OP/98tWjR4rTrAQAAqA5lK4A5jvnX62YNQxTdMNTCquqmKo3MPvHEE5o0aZLeeOMNhYdX/W8YSUlJ2rt3rx5//HG5XC4lJiZq0aJFat26tSTJ5XJ59ZwdNWqUcnNz9dJLL+lvf/ubGjVqpIEDB+qf//xnlWsAAACoCUk94nRh+6b6aWeO7ktdp6ycAi3a6NKV5zAAV50Mswr/Pt+1a1dt3bpVpmkqPj5eQUFBXl9fu3ZttRVY3XJycuR0OuV2uxUZGWl1OQAAoB54/otf9a8vtqhN0wh9Pu5CBTosX4S1VvMlr1VpZHbYsGFVOQ0AAKBeuu2CeM1emaH03w/p2c+3aESf1jwIVk2qNDJrZ4zMAgAAK4x9a40Wbyzt4hRgSCnDOyupR5zFVdVONT4yW2bNmjXavHmzDMNQp06d1LVr19P5dgAAAHWSy52vz3/6ox1pWd/ZC9s3ZYT2NFUpzO7Zs0c33nijvvrqKzVq1EimacrtdmvAgAF699131bRp0+quEwAAwLboO1tzqjT7+J577lFOTo5++ukn7du3T/v379fGjRuVk5Oje++9t7prBAAAsLWyvrPHchgGfWerQZXC7OLFizV9+nR17NjRs69Tp056+eWX9emnn1ZbcQAAAHVBWd/ZYwNt8pAOjMpWgyqF2ZKSknLtuCQpKChIJSUlp10UAABAXZPUI07fTBiouMalo7HNnSygUB2qFGYHDhyo++67T7t27fLs27lzp+6//35dfPHF1VYcAABAXRLjDNMlHaMlSau27rW4mrqhSmH2pZdeUm5uruLj49W2bVu1a9dOCQkJys3N1YsvvljdNQIAANQZvdo0liR9m06YrQ5V6mYQGxurtWvXasmSJfr5559lmqY6deqkSy65pLrrAwAAqFN6JjSRYUhbfz+kPbmH1awh0w1Ox2n1mb300kt16aWXVlctAAAAdZ4zPEidYiL1064cfZu+T1d1aWF1SbZ2ymH2hRde0J///GeFhobqhRdeqPRY2nMBAACcWK82TY6G2b2E2dN0ysvZJiQkaPXq1WrSpIkSEhJO/A0NQ+np6dVWYHVjOVsAAGC1JZt26443V6tN0wgt/dtFVpdT69TIcrYZGRkV/hkAAAC+OT+hsQxDSv/9kHbnHFZ0JPNmq6pK3QyOV1xcrPXr12v//v3V8e0AAADqNGdYkM5uUTriSFeD01OlMDtu3DjNnDlTUmmQvfDCC3XeeecpNjZWX331VXXWBwAAUCf1SmgiSfo2fZ/FldhblcLs+++/ry5dukiSFi5cqG3btunnn3/WuHHj9NBDD1VrgQAAAHVR77alYfbLn/fI5c63uBr7qlKYzc7OVvPmzSVJixYt0vXXX6/27dtrzJgx2rBhQ7UWCAAAUBdl7suTJGXlHFbfKUuVmpZpcUX2VKUwGx0drU2bNqm4uFiLFy/2LJaQl5cnh8NRrQUCAADUNS53vp74eJNnu8SUJs7byAhtFVRp0YTRo0frhhtuUExMjAzD8Cyc8N1336lDhw7VWiAAAEBdk5F9SCXHNUctNk1tycpVjDPMmqJsqkph9tFHH1ViYqK2b9+u66+/XiEhIZIkh8OhCRMmVGuBAAAAdU1CVIQCDJULtJM+3KiXb+mmxJZOawqzoVNeNKGuYNEEAABQG6SmZWrivI0qNk0FGFJEcKByC4oU5DA0/tKz9OcL28gRYFhdpiV8yWunHGbrynK2hFkAAFBbuNz52padp/iocIUGOpQ8b4MW/5QlSeqZ0FhTk85Vy0b1b9pBjYRZlrMFAACoWaZp6r3VO/Towp+Ud6RYDUMD9Y9rOuuqLi2sLs2vaiTM1hWEWQAAUNttyz6kcanrtX77AUnSNV1b6rGrz1ZkaJC1hfmJL3mtWpazBQAAQPWJj4rQe2N7696Lz1SAIc1ft1ODn1uu7zP2yeXO18qt2bTxOqpKI7PXXXedunfvXq5zwdNPP63vv/9e7733XrUVWN0YmQUAAHay5n/7NC51vbbvy1fZ42CmpABDShneWUk94qwsr0bU+MjssmXLdMUVV5Tbf/nll+vrr7+uyrcEAABABbq1bqxF9/bT5YnNZao0yEostFCmSmH24MGDCg4OLrc/KChIOTk5p10UAAAA/tAwNEgjercut7/YNLUtO8+CimqPKoXZxMREpaamltv/7rvvqlOnTqddFAAAALyVLbRwLIdhKD4q3JqCaokqrQD28MMP69prr9XWrVs1cOBASdJ///tfzZ07t1bPlwUAALCrGGeYHh16tiZ99JOk0jmzk4cn1vvlb6s0MnvVVVdpwYIF+u2333T33Xfrb3/7m3bs2KEvvvhCw4YNq+YSAQAAIEnXdmvl+fPSv11UJx/+8lWVRmYl6YorrqjwITAAAADUvObOUKtLqBWq3Gf2wIEDmjFjhiZOnKh9+/ZJktauXaudO3dWW3EAAACoWJb7sNUl1ApVCrM//vij2rdvr3/+8596+umndeDAAUnS/PnzlZycXJ31AQAA4KgP1uzw/Hngs18pNS3TwmpqhyqF2fHjx2vUqFH69ddfFRr6xxD34MGD6TMLAABQA1zufD268CfPNn1mS1UpzKalpenOO+8st79ly5bKyso67aIAAADgLSP7kEqOW7eVPrNVDLOhoaEVLo7wyy+/qGnTpqddFAAAALzRZ7ZiVQqzV199tR5//HEVFhZKkgzDUGZmpiZMmKBrr722WgsEAADAH31my9BntlSVwuwzzzyj33//Xc2aNVN+fr769++vdu3aqWHDhvrHP/5R3TUCAABA9JmtSJX6zEZGRmrFihVaunSp1q5dq5KSEp133nm65JJLqrs+AAAAVIA+s6V8DrNFRUUKDQ3V+vXrNXDgQM9ytgAAAIC/+TzNIDAwUK1bt1ZxcXFN1AMAAACcsirNmf373/+u5ORkz8pfAAAAgBWqNGf2hRde0G+//aYWLVqodevWioiI8Pr62rVrq6U4AAAAoDJVCrPDhg2TYRgyTfPkBwMAAAA1xKcwm5eXpwcffFALFixQYWGhLr74Yr344ouKioqqqfoAAACAE/JpzuwjjzyiOXPm6IorrtBNN92kL774QnfddVdN1QYAAABUyqeR2Xnz5mnmzJm68cYbJUm33HKL+vbtq+LiYjkcjhopEAAAADgRn0Zmt2/frn79+nm2zz//fAUGBmrXrl3VXhgAAABOLMt92OoSagWfwmxxcbGCg4O99gUGBqqoqKhaiwIAAEB5H6zZ4fnzwGe/UmpapoXV1A4+TTMwTVOjRo1SSEiIZ9/hw4c1duxYr/Zc8+bNq74KAQAAIJc7X48u/MmzXWJKE+dt1IXtmyrGGWZhZdbyKcyOHDmy3L4//elP1VYMAAAAKpaRfUglx3VFLTZNbcvOI8yeqtmzZ9dUHQAAAKhEQlSEAgx5BVqHYSg+Kty6omqBKi1nCwAAAP+KcYZp6DktvPYN69qiXo/KSoRZAAAAW3C587XwR+8OUgvW7ZLLnW9RRbUDYRYAAMAGKpszW58RZgEAAGygbM7ssZgzS5gFAACwhRhnmB4derZnO8CQJg9PZM6s1QUAAADg1FzbrZXnz0v/dpGSesRZWE3tQJgFAACwoebOUKtLqBUIswAAALAtwiwAAABsizALAAAA2yLMAgAA2FCW+7DVJdQKhFkAAACb+GDNDs+fBz77lVLTMi2spnYgzAIAANiAy52vRxf+5NkuMaWJ8zaynK3VBQAAAODkWM62YoRZAAAAG2A524oRZgEAAGwgxhmmlOGdvQLtuEvasZyt1QUAAADg1CT1iNM3EwaqR/wZkqRd7gKLK7IeYRYAAMBGYpxhevCyDpKkeWt3aN+hIxZXZC3CLAAAgM30iD9D57RyqqCoRG9/+z+ry7EUYRYAAMBmDMPQmAsSJElvrPqfCoqKLa7IOoRZAAAAGxrSOUbNI0OVfbBA/1rya73tN0uYBQAAsKEgR4DOjWskSXpl2Vb1nbK0Xq4IRpgFAACwIZc7X5//lOXZrq8rghFmAQAAbIgVwUoRZgEAAGyIFcFKEWYBAABsqGxFsDIBhjR5eGK9WxGMMAsAAGBTST3i1NwZKkl6bUR3JfWIs7gi/7M8zE6bNk0JCQkKDQ1Vt27dtHz58hMeO2rUKBmGUe519tln+7FiAACA2iPw6FyDqAYhFldiDUvDbGpqqsaNG6eHHnpI69atU79+/TR48GBlZlbcVuL555+Xy+XyvLZv367GjRvr+uuv93PlAAAAqA0sDbNTp07VmDFjdPvtt6tjx4567rnnFBsbq+nTp1d4vNPpVPPmzT2v1atXa//+/Ro9erSfKwcAAEBtYFmYPXLkiNasWaNBgwZ57R80aJBWrlx5St9j5syZuuSSS9S6desTHlNQUKCcnByvFwAAQF1RdLQ/V/bBAosrsYZlYTY7O1vFxcWKjo722h8dHa2srKwTnPUHl8ulTz/9VLfffnulx6WkpMjpdHpesbGxp1U3AABAbZGalqks92FJ0h1vrmYFMCsYhneDNNM0y+2ryJw5c9SoUSMNGzas0uOSk5Pldrs9r+3bt59OuQAAALWCy52v5HkbPNtmPV0BLNCqC0dFRcnhcJQbhd2zZ0+50drjmaapWbNm6dZbb1VwcHClx4aEhCgkpH4+3QcAAOquylYAq0+9Zi0bmQ0ODla3bt20ZMkSr/1LlixRnz59Kj132bJl+u233zRmzJiaLBEAAKDWYgWwUpZOMxg/frxmzJihWbNmafPmzbr//vuVmZmpsWPHSiqdIjBixIhy582cOVM9e/ZUYmKiv0sGAACoFVgBrJRl0wwkKSkpSXv37tXjjz8ul8ulxMRELVq0yNOdwOVyles563a79cEHH+j555+3omQAAIBaI6lHnP71xa/Kch/WayO665KOlU/VrIsM0zTNkx9Wd+Tk5MjpdMrtdisyMtLqcgAAAE7LBf9cqh3787XgL311bmwjq8upFr7kNcu7GQAAAABVRZgFAACAbRFmAQAAYFuEWQAAANgWYRYAAAC2RZgFAACAbRFmAQAAYFuEWQAAANgWYRYAAAC2RZgFAACAbRFmAQAAYFuEWQAAANgWYRYAAAC2RZgFAACAbRFmAQAAYFuEWQAAANgWYRYAAAC2RZgFAACAbRFmAQAAYFuEWQAAANgWYRYAAAC2RZgFAACAbRFmAQAAYFuEWQAAANgWYRYAAAC2RZgFAACwsaISU5KUfbDA4kqsQZgFAACwqdS0TGW5D0uS7nhztVLTMi2uyP8IswAAADbkcucred4Gz7ZpShPnbZTLnW9hVf5HmAUAALChjOxDOjrDwKPYNLUtO8+agixCmAUAALChhKgIBRje+xyGofiocGsKsghhFgAAwIZinGFKGd7Zsx1gSJOHJyrGGWZhVf5HmAUAALCppB5xau4MlSS9NqK7knrEWVyR/xFmAQAAbCzw6FyDqAYhFldiDcIsAAAAbIswCwAAANsizAIAAMC2CLMAAACwLcIsAACAjRUdXTkh+2CBxZVYgzALAABgU6lpmcpyH5Yk3fHmaqWmZVpckf8RZgEAAGzI5c5X8rwNnm3TlCbO2yiXO9/CqvyPMAsAAGBDGdmHdHSGgUexaWpbdp41BVmEMAsAAGBDCVEROrpegofDMBQfFW5NQRYhzAIAANhQjDNMKcM7e7YDDGny8ETFOMMsrMr/CLMAAAA2ldQjTs2doZKk10Z0V1KPOIsr8j/CLAAAgI0FHp1rENUgxOJKrEGYBQAAgG0RZgEAAGBbhFkAAADYFmEWAAAAtkWYBQAAgG0RZgEAAGBbhFkAAADYFmEWAAAAtkWYBQAAgG0RZgEAAGysqMSUJGUfLLC4EmsQZgEAAGwqNS1TWe7DkqQ73lyt1LRMiyvyP8IsAACADbnc+Uqet8GzbZrSxHkb5XLnW1iV/xFmAQAAbCgj+5COzjDwKDZNbcvOs6YgixBmAQAAbCghKkIBhvc+h2EoPircmoIsQpgFAACwoRhnmFKGd/ZsBxjS5OGJinGGWViV/xFmAQAAbCqpR5yaO0MlSa+N6K6kHnEWV+R/hFkAAAAbCzw61yCqQYjFlViDMAsAAADbIswCAADYGIsmAAAAwJZYNIEwCwAAYEssmlCKMAsAAGBDLJpQijALAABgQxUtmhBgiEUTAAAAUPuVLZrgMP5ItGc2a8CiCQAAALCHpB5xWjFhgP51QxcZkn7ZfVA/Z+VYXZZfEWYBAABsLMYZpmvOa6UhnWMkSa8tS7e4Iv8izAIAANQBY/u3lSR99MMu7TxQfzoaEGYBAADqgM6tnOrbromKSkw9uXBTvWnRRZgFAACoIzo0j5QkffpTlvpOWVovFlEgzAIAANQBLne+Zn+T4dkuqSeLKBBmAQAA6oD6uogCYRYAAKAOqGgRBYdh1PlFFAizAAAAdUDZIgplDEOaPDyxzi+iQJgFAACoI5J6xOmCdk0kSRMu76CkHnEWV1TzCLMAAACwLcvD7LRp05SQkKDQ0FB169ZNy5cvr/T4goICPfTQQ2rdurVCQkLUtm1bzZo1y0/VAgAA1F6paZla8dteSdKUT3+uF625Aq28eGpqqsaNG6dp06apb9++evXVVzV48GBt2rRJcXEVD4vfcMMN2r17t2bOnKl27dppz549Kioq8nPlAAAAtYvLna/keRs826ZKW3Nd2L5pnZ43a2mYnTp1qsaMGaPbb79dkvTcc8/ps88+0/Tp05WSklLu+MWLF2vZsmVKT09X48aNJUnx8fH+LBkAAKBWqqw1V10Os5ZNMzhy5IjWrFmjQYMGee0fNGiQVq5cWeE5H330kbp3766nnnpKLVu2VPv27fXAAw8oP//EzYALCgqUk5Pj9QIAAKhrKmrNJUmNwoP8X4wfWRZms7OzVVxcrOjoaK/90dHRysrKqvCc9PR0rVixQhs3btT8+fP13HPP6f3339df/vKXE14nJSVFTqfT84qNja3W9wEAAFAblLXmchjeiXbCBz/qYEHdnZJp+QNgxnEfuGma5faVKSkpkWEYevvtt3X++edryJAhmjp1qubMmXPC0dnk5GS53W7Pa/v27dX+HgAAAGqDpB5xWjFhgObe0Utz7+ipM8KD9MMOt8b+e40KioqtLq9GWBZmo6Ki5HA4yo3C7tmzp9xobZmYmBi1bNlSTqfTs69jx44yTVM7duyo8JyQkBBFRkZ6vQAAAOqqGGeYerdtot5tozRn9PkKD3ZoxW/Zuj91vYqPn1RbB1gWZoODg9WtWzctWbLEa/+SJUvUp0+fCs/p27evdu3apYMHD3r2bdmyRQEBAWrVqlWN1gsAAGA3XWIb6bVbuyvYEaBFG7L09wUbZZp1K9BaOs1g/PjxmjFjhmbNmqXNmzfr/vvvV2ZmpsaOHSupdIrAiBEjPMfffPPNatKkiUaPHq1Nmzbp66+/1oMPPqjbbrtNYWF19yk9AACAqrrgzCg9f+O5CjCkud9n6pnPf5HLna+VW7Plcp/4IXq7sLQ1V1JSkvbu3avHH39cLpdLiYmJWrRokVq3bi1Jcrlcysz8o9lvgwYNtGTJEt1zzz3q3r27mjRpohtuuEFPPvmkVW8BAACg1hvcOUb/uKazkudt0MtfbtW0L7fKlBRgSCnDO9t62VvDrGtjzSeRk5Mjp9Mpt9vN/FkAAFCv/HPxZk3/Kt1rn8MwtGLCgFrVi9aXvGZ5NwMAAAD4R792TcvtK1tYwa4IswAAAPVEQtPyCys4DEPxUeHWFFQNCLMAAAD1RIwzTJOv6ezZDjCkycMTa9UUA18RZgEAAOqRG8+P04VnRkmS7r6ora0f/pIIswAAAPVO77alYTY9+5DFlZw+wiwAAEA9c25sI0nSuswDltZRHQizAAAA9cw5rZwKMCSX+7B25xy2upzTQpgFAACoZyJCAtU+uqEk+4/OEmYBAADqoa5xjSRJ67bvt7aQ00SYBQAAqIe6xp4hSVrPyCwAAADs5tyjI7M/7nCrqLjE2mJOA2EWAACgHmrXtIEahgQqv7BYW3YftLqcKiPMAgAA1EMBAYbOiXVKsve8WcIsAABAPVUX5s0SZgEAAOqpssUT1m8/YGkdp4MwCwAAUE+VPQT22+8HlXO40NpiqogwCwAAUE9FNQhRbOMwmab043a31eVUCWEWAACgHjv36LzZD9fvlMudb3E1viPMAgAA1GemKUl6b80O9Z2yVKlpmRYX5BvCLAAAQD3lcufr4w0uz3aJKU2ct9FWI7SEWQAAgHoqI/tQ2cCsR7Fpalt2njUFVQFhFgAAoJ5KiIpQgFF+f5MGwf4vpooIswAAAPVUjDNMKcM7y2F4J9onPt6kwuISi6ryjWGaxw8u1205OTlyOp1yu92KjIy0uhwAAADLudz52padp4KiYt399lrlHSnWjT1ilTK8swyjgqHbGuZLXmNkFgAAoJ6LcYapd9smuuisZnrxpq4KMKR307br1a/TrS7tpAizAAAA8Li4Y7QmXdlJkjTl05+16JhuB7VRoNUFAAAAoHYZ1TdB2/bmac7Kbbo/db0CHYYahAQqISpCMc4wq8vzQpgFAABAOQ9f2Uk79ufpi8179Oc310iSAgwpZXhnJfWIs7i6PzDNAAAAAOU4AgwlD+7ota82LqpAmAUAAECFduceLrevti2qQJgFAABAhSpaVMFhGIqPCremoAoQZgEAAFChskUVygQY0uThibXqITDCLAAAAE4oqUec2jaNkCQ9d+O5terhL4kwCwAAgJMIcpRGxiYRIRZXUh5hFgAAALZFmAUAAIBtEWYBAABgW4RZAAAAVKqwuESStPdQgcWVlEeYBQAAwAmlpmVq6++HJEn3vbteqWmZFlfkjTALAACACrnc+Uqet8GzbbKcLQAAAOwiI/uQSkzvfSxnCwAAAFtgOVsAAADYVowzTNd0bem1b1jXFixnCwAAgNrP5c7X/HU7vfYtWLeLObMAAACo/ZgzCwAAANtiziwAAABsizmzAAAAsC3mzAIAAMC2mDMLAAAA22LOLAAAAGwrxhmmlOGd5TBKE63DMDR5eGKtmjMbaHUBAAAAqL2SesTpwvZNtS07T/FR4bUqyEqEWQAAAJxEjDOs1oXYMkwzAAAAgG0RZgEAAGBbhFkAAADYFmEWAAAAtkWYBQAAgG0RZgEAAGBbhFkAAADYFmEWAAAAtkWYBQAAgG0RZgEAAGBbhFkAAADYFmEWAAAAtkWYBQAAgG0RZgEAAGBbhFkAAADYVqDVBfibaZqSpJycHIsrAQAAQEXKclpZbqtMvQuzubm5kqTY2FiLKwEAAEBlcnNz5XQ6Kz3GME8l8tYhJSUl2rVrlxo2bCjDMPxyzZycHMXGxmr79u2KjIz0yzVRfbh/9sc9tD/uob1x/+zP3/fQNE3l5uaqRYsWCgiofFZsvRuZDQgIUKtWrSy5dmRkJL/ENsb9sz/uof1xD+2N+2d//ryHJxuRLcMDYAAAALAtwiwAAABsizDrByEhIXrkkUcUEhJidSmoAu6f/XEP7Y97aG/cP/urzfew3j0ABgAAgLqDkVkAAADYFmEWAAAAtkWYBQAAgG0RZgEAAGBbhNlqMG3aNCUkJCg0NFTdunXT8uXLKz1+2bJl6tatm0JDQ9WmTRu98sorfqoUJ+LLPZw3b54uvfRSNW3aVJGRkerdu7c+++wzP1aLivj6e1jmm2++UWBgoM4999yaLRAn5es9LCgo0EMPPaTWrVsrJCREbdu21axZs/xULY7n6/17++231aVLF4WHhysmJkajR4/W3r17/VQtjvf1119r6NChatGihQzD0IIFC056Tq3JMyZOy7vvvmsGBQWZr7/+urlp0ybzvvvuMyMiIsz//e9/FR6fnp5uhoeHm/fdd5+5adMm8/XXXzeDgoLM999/38+Vo4yv9/C+++4z//nPf5rff/+9uWXLFjM5OdkMCgoy165d6+fKUcbXe1jmwIEDZps2bcxBgwaZXbp08U+xqFBV7uFVV11l9uzZ01yyZImZkZFhfvfdd+Y333zjx6pRxtf7t3z5cjMgIMB8/vnnzfT0dHP58uXm2WefbQ4bNszPlaPMokWLzIceesj84IMPTEnm/PnzKz2+NuUZwuxpOv/8882xY8d67evQoYM5YcKECo//v//7P7NDhw5e++68806zV69eNVYjKufrPaxIp06dzMcee6y6S8Mpquo9TEpKMv/+97+bjzzyCGHWYr7ew08//dR0Op3m3r17/VEeTsLX+/f000+bbdq08dr3wgsvmK1ataqxGnHqTiXM1qY8wzSD03DkyBGtWbNGgwYN8to/aNAgrVy5ssJzVq1aVe74yy67TKtXr1ZhYWGN1YqKVeUeHq+kpES5ublq3LhxTZSIk6jqPZw9e7a2bt2qRx55pKZLxElU5R5+9NFH6t69u5566im1bNlS7du31wMPPKD8/Hx/lIxjVOX+9enTRzt27NCiRYtkmqZ2796t999/X1dccYU/SkY1qE15JtCvV6tjsrOzVVxcrOjoaK/90dHRysrKqvCcrKysCo8vKipSdna2YmJiaqxelFeVe3i8Z599VocOHdINN9xQEyXiJKpyD3/99VdNmDBBy5cvV2Ag/xm0WlXuYXp6ulasWKHQ0FDNnz9f2dnZuvvuu7Vv3z7mzfpZVe5fnz599PbbbyspKUmHDx9WUVGRrrrqKr344ov+KBnVoDblGUZmq4FhGF7bpmmW23ey4yvaD//x9R6WmTt3rh599FGlpqaqWbNmNVUeTsGp3sPi4mLdfPPNeuyxx9S+fXt/lYdT4MvvYUlJiQzD0Ntvv63zzz9fQ4YM0dSpUzVnzhxGZy3iy/3btGmT7r33Xk2aNElr1qzR4sWLlZGRobFjx/qjVFST2pJnGJI4DVFRUXI4HOX+5rlnz55yf1sp07x58wqPDwwMVJMmTWqsVlSsKvewTGpqqsaMGaP33ntPl1xySU2WiUr4eg9zc3O1evVqrVu3Tn/9618llQYj0zQVGBiozz//XAMHDvRL7ShVld/DmJgYtWzZUk6n07OvY8eOMk1TO3bs0JlnnlmjNeMPVbl/KSkp6tu3rx588EFJ0jnnnKOIiAj169dPTz75JP9KaQO1Kc8wMnsagoOD1a1bNy1ZssRr/5IlS9SnT58Kz+ndu3e54z///HN1795dQUFBNVYrKlaVeyiVjsiOGjVK77zzDnO8LObrPYyMjNSGDRu0fv16z2vs2LE666yztH79evXs2dNfpeOoqvwe9u3bV7t27dLBgwc9+7Zs2aKAgAC1atWqRuuFt6rcv7y8PAUEeEcQh8Mh6Y/RPdRutSrP+P2RszqmrB3JzJkzzU2bNpnjxo0zIyIizG3btpmmaZoTJkwwb731Vs/xZa0s7r//fnPTpk3mzJkzac1lMV/v4TvvvGMGBgaaL7/8sulyuTyvAwcOWPUW6j1f7+Hx6GZgPV/vYW5urtmqVSvzuuuuM3/66Sdz2bJl5plnnmnefvvtVr2Fes3X+zd79mwzMDDQnDZtmrl161ZzxYoVZvfu3c3zzz/fqrdQ7+Xm5prr1q0z161bZ0oyp06daq5bt87TXq025xnCbDV4+eWXzdatW5vBwcHmeeedZy5btszztZEjR5r9+/f3Ov6rr74yu3btagYHB5vx8fHm9OnT/VwxjufLPezfv78pqdxr5MiR/i8cHr7+Hh6LMFs7+HoPN2/ebF5yySVmWFiY2apVK3P8+PFmXl6en6tGGV/v3wsvvGB26tTJDAsLM2NiYsxbbrnF3LFjh5+rRpkvv/yy0v9vq815xjBNxvMBAABgT8yZBQAAgG0RZgEAAGBbhFkAAADYFmEWAAAAtkWYBQAAgG0RZgEAAGBbhFkAAADYFmEWAAAAtkWYBYB6LD4+Xs8995xn2zAMLViwwLJ6AMBXhFkAsMioUaNkGIYMw1BgYKDi4uJ01113af/+/VaXBgC2QZgFAAtdfvnlcrlc2rZtm2bMmKGFCxfq7rvvtrosALANwiwAWCgkJETNmzdXq1atNGjQICUlJenzzz/3fH327Nnq2LGjQkND1aFDB02bNs3r/B07dujGG29U48aNFRERoe7du+u7776TJG3dulVXX321oqOj1aBBA/Xo0UNffPGFX98fANS0QKsLAACUSk9P1+LFixUUFCRJev311/XII4/opZdeUteuXbVu3TrdcccdioiI0MiRI3Xw4EH1799fLVu21EcffaTmzZtr7dq1KikpkSQdPHhQQ4YM0ZNPPqnQ0FC98cYbGjp0qH755RfFxcVZ+VYBoNoQZgHAQh9//LEaNGig4uJiHT58WJI0depUSdITTzyhZ599VsOHD5ckJSQkaNOmTXr11Vc1cuRIvfPOO/r999+Vlpamxo0bS5LatWvn+d5dunRRly5dPNtPPvmk5s+fr48++kh//etf/fUWAaBGEWYBwEIDBgzQ9OnTlZeXpxkzZmjLli2655579Pvvv2v79u0aM2aM7rjjDs/xRUVFcjqdkqT169era9euniB7vEOHDumxxx7Txx9/rF27dqmoqEj5+fnKzMz0y3sDAH8gzAKAhSIiIjyjqS+88IIGDBigxx57zDNy+vrrr6tnz55e5zgcDklSWFhYpd/7wQcf1GeffaZnnnlG7dq1U1hYmK677jodOXKkBt4JAFiDMAsAtcgjjzyiwYMH66677lLLli2Vnp6uW265pcJjzznnHM2YMUP79u2rcHR2+fLlGjVqlK655hpJpXNot23bVpPlA4Df0c0AAGqRiy66SGeffbYmT56sRx99VCkpKXr++ee1ZcsWbdiwQbNnz/bMqb3pppvUvHlzDRs2TN98843S09P1wQcfaNWqVZJK58/OmzdP69ev1w8//KCbb77Z83AYANQVhFkAqGXGjx+v119/XZdddplmzJihOXPmqHPnzurfv7/mzJmjhIQESVJwcLA+//xzNWvWTEOGDFHnzp01ZcoUzzSEf/3rXzrjjDPUp08fDR06VJdddpnOO+88K98aAFQ7wzRN0+oiAAAAgKpgZBYAAAC2RZgFAACAbRFmAQAAYFuEWQAAANgWYRYAAAC2RZgFAACAbRFmAQAAYFuEWQAAANgWYRYAAAC2RZgFAACAbRFmAQAAYFv/H6UtarG4Ahb0AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Generate synthetic data for binary classification\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Train a RandomForest classifier\n",
    "classifier = RandomForestClassifier(random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "y_scores = classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# [Your Code Here] - Generate precision and recall values for various thresholds\n",
    "# Compute the presision recall-curve\n",
    "precision, recall, threshold = precision_recall_curve(y_test, y_scores)\n",
    "\n",
    "\n",
    "# Plot the precision-recall curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, marker='.')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198463ec",
   "metadata": {},
   "source": [
    "## Question 11\n",
    "\n",
    "You are tasked with enhancing the robustness of a logistic regression model by incorporating feature scaling. You're currently working with a dataset that has significantly varying scales among its features, which can affect the model's performance. Below is a preliminary setup for the logistic regression model. Identify the correct sequence of steps to integrate feature scaling into the modelling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9bd4e937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# [Your Code Here] - Apply feature scaling to the training data\n",
    "# Standardize the training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test) # [Your Code Here] - Apply the same scaling to the test data\n",
    "\n",
    "# [Your Code Here] - Fit the model on the scaled training data\n",
    "lr.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab9ab5e",
   "metadata": {},
   "source": [
    "# Question 12\n",
    "\n",
    "You are fine-tuning a support vector machine (SVM) classifier to categorise images based on their content. The dataset consists of various animal images, and you suspect that different kernel functions might yield better classification accuracy. You decide to test which SVM kernel—linear or radial basis function (RBF)—works best for your specific dataset. Below is your initial code setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fdc8d1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of the SVM with the linear kernel is: 0.9822222222222222\n",
      "The accuracy score of the SVM with the RBF kernel is: 0.9866666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load a dataset of digit images\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize two SVM classifiers, one with a linear kernel and another with an RBF kernel\n",
    "svm_linear = SVC(kernel='linear')\n",
    "svm_rbf = SVC(kernel='rbf')\n",
    "\n",
    "# [Your Code Here] - Train both classifiers on the training data\n",
    "svm_linear.fit(X_train, y_train)\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "\n",
    "# [Your Code Here] - Predict the test set results with both classifiers\n",
    "svm_linear_pred = svm_linear.predict(X_test)\n",
    "svm_rbf_pred = svm_rbf.predict(X_test)\n",
    "\n",
    "# [Your Code Here] - Calculate and print the accuracy scores for both classifiers\n",
    "print(f\"The accuracy score of the SVM with the linear kernel is: {accuracy_score(y_test, svm_linear_pred)}\")\n",
    "print(f\"The accuracy score of the SVM with the RBF kernel is: {accuracy_score(y_test, svm_rbf_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e097f7ae",
   "metadata": {},
   "source": [
    "Which of the following options correctly completes the task of training both SVM classifiers, predicting the test set results, and calculating the accuracy for each"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182f3dfa",
   "metadata": {},
   "source": [
    "## Question 13 \n",
    "\n",
    "You are currently evaluating two classifiers, K-Nearest Neighbours (KNN) and Naive Bayes, for a project that involves classifying texts into different categories based on their content. To finalise your model selection, you decide to visually compare their performance using a bar chart. Below is the setup for calculating the accuracy of both models on your dataset. Complete the code by adding the necessary lines to plot the accuracies in a bar chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ed671d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "data = fetch_20newsgroups(subset='all')\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Create train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorise text data\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialise classifiers\n",
    "knn = KNeighborsClassifier()\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# Train classifiers\n",
    "knn.fit(X_train_tfidf, y_train)\n",
    "nb.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict and calculate accuracy\n",
    "knn_accuracy = accuracy_score(y_test, knn.predict(X_test_tfidf))\n",
    "nb_accuracy = accuracy_score(y_test, nb.predict(X_test_tfidf))\n",
    "\n",
    "# [Your code here] - Plot the accuracies in a bar chart\n",
    "# Plot the accuracies in a bar chart\n",
    "classifiers = ['K-Nearest Neighbors', 'Naive Bayes']\n",
    "accuracies = [knn_accuracy, nb_accuracy]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(classifiers, accuracies, color=['blue', 'green'])\n",
    "plt.xlabel('Classifier')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Comparison of KNN and Naive Bayes')\n",
    "plt.ylim(0, 1)  # Set y-axis limit to ensure accuracy values are within the plot range\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aca8e77",
   "metadata": {},
   "source": [
    "Which snippet of code will correctly plot the accuracies of KNN and Naive Bayes classifiers in a bar chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00db7298",
   "metadata": {},
   "source": [
    "## Question 14\n",
    "\n",
    "You are tasked with evaluating a simple binary classification model using a confusion matrix. The dataset involves predicting whether a given email is spam or not. To better understand the model's performance, you plan to extract specific metrics from the confusion matrix, specifically True Positives (TP) and False Positives (FP). Below is your initial code setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a61dd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The True Positive is: 113\n",
      "The False Positive is: 8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Generate synthetic binary classification data\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "classifier = RandomForestClassifier(random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# [Your code here] - Extract and print True Positives and False Positives\n",
    "TP = cm[1][1]\n",
    "FP = cm[0,1]\n",
    "\n",
    "print(f\"The True Positive is: {TP}\")\n",
    "print(f\"The False Positive is: {FP}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faf3d05",
   "metadata": {},
   "source": [
    "Which snippet of code correctly extracts and prints the True Positives (TP) and False Positives (FP) from the confusion matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54632b17",
   "metadata": {},
   "source": [
    "Which snippet of code correctly completes the setup to create a pipeline including `PolynomialFeatures` and `LogisticRegression`, fits it on the training data, and makes predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3781c44",
   "metadata": {},
   "source": [
    "## Question 15 (Medium)\n",
    "\n",
    "You are refining a logistic regression model to predict customer churn. The dataset includes various customer interaction metrics. To enhance your model, explore how polynomial features can improve prediction accuracy. This approach allows the model to capture complex interactions between variables. \n",
    "\n",
    "Here is your setup: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08305212",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of informative, redundant and repeated features must sum to less than the number of total features",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PolynomialFeatures\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Generate synthetic data for binary classification\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m X, y \u001b[38;5;241m=\u001b[39m make_classification(n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, n_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, n_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Split the data into training and testing sets\u001b[39;00m\n\u001b[0;32m     10\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\datasets\\_samples_generator.py:200\u001b[0m, in \u001b[0;36mmake_classification\u001b[1;34m(n_samples, n_features, n_informative, n_redundant, n_repeated, n_classes, n_clusters_per_class, weights, flip_y, class_sep, hypercube, shift, scale, shuffle, random_state)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# Count features, clusters and samples\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_informative \u001b[38;5;241m+\u001b[39m n_redundant \u001b[38;5;241m+\u001b[39m n_repeated \u001b[38;5;241m>\u001b[39m n_features:\n\u001b[1;32m--> 200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of informative, redundant and repeated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures must sum to less than the number of total\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m features\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    204\u001b[0m     )\n\u001b[0;32m    205\u001b[0m \u001b[38;5;66;03m# Use log2 to avoid overflow errors\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_informative \u001b[38;5;241m<\u001b[39m np\u001b[38;5;241m.\u001b[39mlog2(n_classes \u001b[38;5;241m*\u001b[39m n_clusters_per_class):\n",
      "\u001b[1;31mValueError\u001b[0m: Number of informative, redundant and repeated features must sum to less than the number of total features"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Generate synthetic data for binary classification\n",
    "X, y = make_classification(n_samples=1000, n_features=3, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Apply polynomial features manually\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_poly, y_train)\n",
    "y_pred = model.predict(X_test_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866a2e94",
   "metadata": {},
   "source": [
    "What is the correct procedure to fit a logistic regression model on the training data after transforming it with polynomial features, and how should predictions be made on the test data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fd094b-0fee-46f1-a4b8-73766813c42b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  \n",
    "\n",
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/ExploreAI_logos/EAI_Blue_Dark.png\"  style=\"width:200px\";/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
